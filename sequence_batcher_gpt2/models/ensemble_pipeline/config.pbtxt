name: "ensemble_pipeline"
platform: "ensemble"
max_batch_size: 4
input [
{
    name: "INPUT_TOKENS"
    data_type: TYPE_STRING
    dims: [ 1 ]
}
]
output [
{
    name: "NEXT_TOKENS"
    data_type: TYPE_STRING
    dims: [ 1 ]
}
]
ensemble_scheduling {
    step [
        {
            model_name: "tokenizer"
            model_version: -1
            input_map {
                key: "INPUT_TOKENS"
                value: "INPUT_TOKENS"
            }
            output_map {
                key: "ENCODED_INPUT_TOKENS"
                value: "ENCODED_INPUT_TOKENS"
            }
        },
#        {
#            model_name: "generator_torchscript"
#            model_version: -1
#            input_map {
#                key: "INPUT__0"
#                value: "ENCODED_INPUT_TOKENS"
#            }
#            output_map {
#                key: "OUTPUT__0"
#                value: "MODEL_OUTPUT_LOGITS"
#            }
#        },
        {
            model_name: "generator_onnx"
            model_version: -1
            input_map {
                key: "INPUT_TOKEN_IDS"
                value: "ENCODED_INPUT_TOKENS"
            }
            output_map {
                key: "OUTPUT_LOGITS"
                value: "MODEL_OUTPUT_LOGITS"
            }
        },
        {
            model_name: "detokenizer"
            model_version: -1
            input_map {
                key: "INPUT_LOGITS"
                value: "MODEL_OUTPUT_LOGITS"
            }
            output_map {
                key: "OUTPUT_TOKENS"
                value: "NEXT_TOKENS"
            }
        }
    ]
}
